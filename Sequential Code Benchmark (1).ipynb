{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0f754d8-c70e-476d-936d-b2c98978790a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/fellwakh/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ Loading dataset...\n",
      "âœ… Dataset loaded successfully: 10635 rows\n",
      "\n",
      "===============================================\n",
      "ğŸ·ï¸  TOP 10 MOST FREQUENT GENRES\n",
      "===============================================\n",
      "  fiction                   7268\n",
      "  classics                  5467\n",
      "  20th-century              3207\n",
      "  non-fiction               3035\n",
      "  literature                2936\n",
      "  history                   2936\n",
      "  historical-fiction        2632\n",
      "  novels                    2366\n",
      "  historical                2262\n",
      "  romance                   2149\n",
      "\n",
      "===============================================\n",
      "ğŸŒ OVERALL TEXT ANALYSIS (All Books Combined)\n",
      "===============================================\n",
      "\n",
      "ğŸ”¹ Top 15 Words:\n",
      "  the                  35067507\n",
      "  of                   18516551\n",
      "  and                  18392449\n",
      "  to                   15395077\n",
      "  a                    12816898\n",
      "  in                   10117560\n",
      "  i                    7692484\n",
      "  that                 6994246\n",
      "  he                   6969040\n",
      "  was                  6543660\n",
      "  it                   6263874\n",
      "  his                  5327421\n",
      "  with                 4536514\n",
      "  you                  4466103\n",
      "  as                   4446074\n",
      "\n",
      "===============================================\n",
      "ğŸ“Š TF-IDF TOP TERMS (Overall Importance)\n",
      "===============================================\n",
      "   came\n",
      "   come\n",
      "   day\n",
      "   did\n",
      "   en\n",
      "   et\n",
      "   good\n",
      "   great\n",
      "   know\n",
      "   la\n",
      "   le\n",
      "   like\n",
      "   little\n",
      "   man\n",
      "   men\n",
      "   mr\n",
      "   old\n",
      "   que\n",
      "   said\n",
      "   time\n",
      "\n",
      "===============================================\n",
      "â±ï¸  PROCESSING TIME SUMMARY\n",
      "===============================================\n",
      "Total rows processed: 10635\n",
      "Elapsed time: 8 min 21 sec\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import ast\n",
    "import time\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "# ğŸ•’ Ø¨Ø¯Ø¡ Ø§Ù„Ù…Ø¤Ù‚Øª\n",
    "start_time = time.time()\n",
    "\n",
    "# ğŸ§¾ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù\n",
    "print(\"ğŸ“‚ Loading dataset...\")\n",
    "df = pd.read_csv(\"/Users/fellwakh/Downloads/newpar/books_and_genres.csv\")\n",
    "\n",
    "# Ø­Ø°Ù Ø§Ù„Ø¹Ù…ÙˆØ¯ Ø§Ù„Ø²Ø§Ø¦Ø¯ Ù„Ùˆ Ù…ÙˆØ¬ÙˆØ¯\n",
    "if \"Unnamed: 0\" in df.columns:\n",
    "    df = df.drop(columns=[\"Unnamed: 0\"])\n",
    "\n",
    "print(f\"âœ… Dataset loaded successfully: {len(df)} rows\\n\")\n",
    "\n",
    "# ğŸ§¹ ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†ØµÙˆØµ\n",
    "def clean_text(text):\n",
    "    text = re.sub(r\"[^a-zA-Z\\s]\", \" \", str(text))\n",
    "    return text.lower()\n",
    "\n",
    "df[\"clean_text\"] = df[\"text\"].apply(clean_text)\n",
    "\n",
    "# ğŸ­ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø£Ø¯Ø¨ÙŠØ©\n",
    "def extract_genres(genres_str):\n",
    "    try:\n",
    "        genres = ast.literal_eval(genres_str)\n",
    "        if isinstance(genres, (set, list)):\n",
    "            return list(genres)\n",
    "        else:\n",
    "            return []\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "df[\"genre_list\"] = df[\"genres\"].apply(extract_genres)\n",
    "\n",
    "# ===================================================\n",
    "# ğŸ·ï¸  TOP 10 MOST FREQUENT GENRES\n",
    "# ===================================================\n",
    "all_genres = [g for sublist in df[\"genre_list\"] for g in sublist]\n",
    "genre_freq = Counter(all_genres).most_common(10)\n",
    "\n",
    "print(\"===============================================\")\n",
    "print(\"ğŸ·ï¸  TOP 10 MOST FREQUENT GENRES\")\n",
    "print(\"===============================================\")\n",
    "for g, c in genre_freq:\n",
    "    print(f\"  {g:<25} {c}\")\n",
    "\n",
    "# ===================================================\n",
    "# ğŸ”  TOP 15 WORDS\n",
    "# ===================================================\n",
    "print(\"\\n===============================================\")\n",
    "print(\"ğŸŒ OVERALL TEXT ANALYSIS (All Books Combined)\")\n",
    "print(\"===============================================\")\n",
    "\n",
    "# Ø¬Ù…Ø¹ ÙƒÙ„ Ø§Ù„Ù†ØµÙˆØµ ÙÙŠ Ù†Øµ ÙˆØ§Ø­Ø¯\n",
    "all_text = \" \".join(df[\"clean_text\"])\n",
    "all_words = all_text.split()\n",
    "\n",
    "# ğŸ”¹ Ø£ÙƒØ«Ø± 15 ÙƒÙ„Ù…Ø© Ø´ÙŠÙˆØ¹Ù‹Ø§\n",
    "word_freq = Counter(all_words).most_common(15)\n",
    "\n",
    "print(\"\\nğŸ”¹ Top 15 Words:\")\n",
    "for w, c in word_freq:\n",
    "    print(f\"  {w:<20} {c}\")\n",
    "\n",
    "# ===================================================\n",
    "# ğŸ§® TF-IDF (Overall Important Terms)\n",
    "# ===================================================\n",
    "print(\"\\n===============================================\")\n",
    "print(\"ğŸ“Š TF-IDF TOP TERMS (Overall Importance)\")\n",
    "print(\"===============================================\")\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\", max_features=20)\n",
    "tfidf_matrix = vectorizer.fit_transform(df[\"clean_text\"])\n",
    "tfidf_terms = vectorizer.get_feature_names_out()\n",
    "\n",
    "for term in tfidf_terms:\n",
    "    print(\"  \", term)\n",
    "\n",
    "# ğŸ•’ Ø­Ø³Ø§Ø¨ Ø§Ù„Ø²Ù…Ù† Ø§Ù„Ù…Ø³ØªØºØ±Ù‚\n",
    "end_time = time.time()\n",
    "elapsed = end_time - start_time\n",
    "minutes = int(elapsed // 60)\n",
    "seconds = int(elapsed % 60)\n",
    "\n",
    "print(\"\\n===============================================\")\n",
    "print(\"â±ï¸  PROCESSING TIME SUMMARY\")\n",
    "print(\"===============================================\")\n",
    "print(f\"Total rows processed: {len(df)}\")\n",
    "print(f\"Elapsed time: {minutes} min {seconds} sec\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b65579f9-92d5-4eed-9deb-d9256adc0ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/fellwakh/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "Sequential Benchmarking Results\n",
      "===============================================\n",
      "Trial 1: 8 min 13 sec  |  Avg CPU: 11.2%\n",
      "Trial 2: 14 min 13 sec  |  Avg CPU: 11.8%\n",
      "Trial 3: 12 min 23 sec  |  Avg CPU: 12.9%\n",
      "-----------------------------------------------\n",
      "Average time over 3 runs: 11 min 36 sec\n",
      "Average CPU utilization: 12.0%\n",
      "Total rows processed: 10635\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import ast\n",
    "import time\n",
    "import statistics\n",
    "import psutil\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "import threading\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "# ===== Helper Functions =====\n",
    "def clean_text(text):\n",
    "    text = re.sub(r\"[^a-zA-Z\\s]\", \" \", str(text))\n",
    "    return text.lower()\n",
    "\n",
    "def extract_genres(genres_str):\n",
    "    try:\n",
    "        genres = ast.literal_eval(genres_str)\n",
    "        if isinstance(genres, (set, list)):\n",
    "            return list(genres)\n",
    "        else:\n",
    "            return []\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "# ===== Function to Monitor CPU Utilization =====\n",
    "def monitor_cpu(stop_flag, usage_list):\n",
    "    while not stop_flag.is_set():\n",
    "        usage_list.append(psutil.cpu_percent(interval=0.5))\n",
    "\n",
    "# ===== Benchmarking Loop =====\n",
    "num_trials = 3\n",
    "execution_times = []\n",
    "cpu_usages = []\n",
    "\n",
    "print(\"===============================================\")\n",
    "print(\"Sequential Benchmarking Results\")\n",
    "print(\"===============================================\")\n",
    "\n",
    "for i in range(num_trials):\n",
    "    start = time.time()\n",
    "\n",
    "    # Start CPU monitor thread\n",
    "    stop_flag = threading.Event()\n",
    "    usage_list = []\n",
    "    monitor_thread = threading.Thread(target=monitor_cpu, args=(stop_flag, usage_list))\n",
    "    monitor_thread.start()\n",
    "\n",
    "    # --- Run your full pipeline here ---\n",
    "    df = pd.read_csv(\"/Users/fellwakh/Downloads/newpar/books_and_genres.csv\")\n",
    "    if \"Unnamed: 0\" in df.columns:\n",
    "        df = df.drop(columns=[\"Unnamed: 0\"])\n",
    "\n",
    "    df[\"clean_text\"] = df[\"text\"].apply(clean_text)\n",
    "    df[\"genre_list\"] = df[\"genres\"].apply(extract_genres)\n",
    "\n",
    "    # Word frequency\n",
    "    all_text = \" \".join(df[\"clean_text\"])\n",
    "    all_words = all_text.split()\n",
    "    word_freq = Counter(all_words).most_common(15)\n",
    "\n",
    "    # TF-IDF\n",
    "    vectorizer = TfidfVectorizer(stop_words=\"english\", max_features=20)\n",
    "    tfidf_matrix = vectorizer.fit_transform(df[\"clean_text\"])\n",
    "    tfidf_terms = vectorizer.get_feature_names_out()\n",
    "\n",
    "    # Stop CPU monitor\n",
    "    stop_flag.set()\n",
    "    monitor_thread.join()\n",
    "\n",
    "    end = time.time()\n",
    "    elapsed = end - start\n",
    "    avg_cpu = statistics.mean(usage_list) if usage_list else 0\n",
    "\n",
    "    execution_times.append(elapsed)\n",
    "    cpu_usages.append(avg_cpu)\n",
    "\n",
    "    minutes = int(elapsed // 60)\n",
    "    seconds = int(elapsed % 60)\n",
    "    print(f\"Trial {i+1}: {minutes} min {seconds} sec  |  Avg CPU: {avg_cpu:.1f}%\")\n",
    "\n",
    "# ===== Summary =====\n",
    "avg_time = statistics.mean(execution_times)\n",
    "avg_cpu_total = statistics.mean(cpu_usages)\n",
    "rows = len(df)\n",
    "\n",
    "for idx, (t, c) in enumerate(zip(execution_times, cpu_usages), 1):\n",
    "    m, s = divmod(t, 60)\n",
    "    \n",
    "\n",
    "avg_m, avg_s = divmod(avg_time, 60)\n",
    "print(\"-----------------------------------------------\")\n",
    "print(f\"Average time over {num_trials} runs: {int(avg_m)} min {int(avg_s)} sec\")\n",
    "print(f\"Average CPU utilization: {avg_cpu_total:.1f}%\")\n",
    "print(f\"Total rows processed: {rows}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c067b3ec-3f8d-48e6-89a0-8a86b607b49b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STARTING BENCHMARK: 3 TRIALS\n",
      "============================================================\n",
      "\n",
      "Running Trial 1/3...\n",
      "  Trial 1 completed in 473.8689s\n",
      "Running Trial 2/3...\n",
      "  Trial 2 completed in 480.5118s\n",
      "Running Trial 3/3...\n",
      "  Trial 3 completed in 485.9123s\n",
      "\n",
      "============================================================\n",
      "BENCHMARK RESULTS - AVERAGE OF 3 TRIALS\n",
      "============================================================\n",
      "\n",
      "LOAD                 18.1296s\n",
      "CLEAN                30.8228s\n",
      "EXTRACT_GENRES       0.1474s\n",
      "GENRES_ANALYSIS      0.0038s\n",
      "WORDS_ANALYSIS       157.9542s\n",
      "TFIDF                273.0392s\n",
      "TOTAL                480.0977s\n",
      "\n",
      "==============================\n",
      "SUMMARY\n",
      "==============================\n",
      "Total Rows Processed:  10635\n",
      "Average Total Time:    480.0977s\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import ast\n",
    "import time\n",
    "import sys\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "import statistics\n",
    "\n",
    "nltk.download(\"punkt\", quiet=True)\n",
    "\n",
    "# Store results for each trial\n",
    "trial_results = []\n",
    "\n",
    "def run_analysis_trial(trial_num):\n",
    "    \n",
    "    trial_start = time.time()\n",
    "    timing = {}\n",
    "    \n",
    "    # Load dataset\n",
    "    load_start = time.time()\n",
    "    df = pd.read_csv(\"/Users/fellwakh/Downloads/newpar/books_and_genres.csv\")\n",
    "    if \"Unnamed: 0\" in df.columns:\n",
    "        df = df.drop(columns=[\"Unnamed: 0\"])\n",
    "    timing[\"load\"] = time.time() - load_start\n",
    "    \n",
    "    # Clean texts\n",
    "    clean_start = time.time()\n",
    "    def clean_text(text):\n",
    "        text = re.sub(r\"[^a-zA-Z\\s]\", \" \", str(text))\n",
    "        return text.lower()\n",
    "    df[\"clean_text\"] = df[\"text\"].apply(clean_text)\n",
    "    timing[\"clean\"] = time.time() - clean_start\n",
    "    \n",
    "    # Extract genres\n",
    "    extract_start = time.time()\n",
    "    def extract_genres(genres_str):\n",
    "        try:\n",
    "            genres = ast.literal_eval(genres_str)\n",
    "            if isinstance(genres, (set, list)):\n",
    "                return list(genres)\n",
    "            else:\n",
    "                return []\n",
    "        except:\n",
    "            return []\n",
    "    df[\"genre_list\"] = df[\"genres\"].apply(extract_genres)\n",
    "    timing[\"extract_genres\"] = time.time() - extract_start\n",
    "    \n",
    "    # Top 10 genres\n",
    "    genres_start = time.time()\n",
    "    all_genres = [g for sublist in df[\"genre_list\"] for g in sublist]\n",
    "    genre_freq = Counter(all_genres).most_common(10)\n",
    "    timing[\"genres_analysis\"] = time.time() - genres_start\n",
    "    \n",
    "    # Top 15 words\n",
    "    words_start = time.time()\n",
    "    all_text = \" \".join(df[\"clean_text\"])\n",
    "    all_words = all_text.split()\n",
    "    word_freq = Counter(all_words).most_common(15)\n",
    "    timing[\"words_analysis\"] = time.time() - words_start\n",
    "    \n",
    "    # TF-IDF\n",
    "    tfidf_start = time.time()\n",
    "    vectorizer = TfidfVectorizer(stop_words=\"english\", max_features=20)\n",
    "    tfidf_matrix = vectorizer.fit_transform(df[\"clean_text\"])\n",
    "    tfidf_terms = vectorizer.get_feature_names_out()\n",
    "    timing[\"tfidf\"] = time.time() - tfidf_start\n",
    "    \n",
    "    timing[\"total\"] = time.time() - trial_start\n",
    "    \n",
    "    return {\n",
    "        \"trial\": trial_num,\n",
    "        \"rows\": len(df),\n",
    "        \"timing\": timing\n",
    "    }\n",
    "\n",
    "\n",
    "# RUN 3 TRIALS\n",
    "print(\"=\" * 60)\n",
    "print(\"STARTING BENCHMARK: 3 TRIALS\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "\n",
    "for trial in range(1, 4):\n",
    "    print(f\"Running Trial {trial}/3...\")\n",
    "    try:\n",
    "        result = run_analysis_trial(trial)\n",
    "        trial_results.append(result)\n",
    "        print(f\"  Trial {trial} completed in {result['timing']['total']:.4f}s\")\n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ Trial {trial} failed: {e}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "print()\n",
    "print(\"=\" * 60)\n",
    "print(\"BENCHMARK RESULTS - AVERAGE OF 3 TRIALS\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "\n",
    "# Extract timing data for all trials\n",
    "all_timings = {key: [] for key in trial_results[0][\"timing\"].keys()}\n",
    "for result in trial_results:\n",
    "    for key, value in result[\"timing\"].items():\n",
    "        all_timings[key].append(value)\n",
    "\n",
    "# Calculate averages\n",
    "avg_results = []\n",
    "for task, times in all_timings.items():\n",
    "    avg = statistics.mean(times)\n",
    "    avg_results.append({\n",
    "        \"Task\": task.upper(),\n",
    "        \"Average Time (s)\": f\"{avg:.4f}\"\n",
    "    })\n",
    "    print(f\"{task.upper():<20} {avg:.4f}s\")\n",
    "\n",
    "print()\n",
    "print(\"=\" * 30)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "avg_total = statistics.mean(all_timings[\"total\"])\n",
    "print(f\"Total Rows Processed:  {trial_results[0]['rows']}\")\n",
    "print(f\"Average Total Time:    {avg_total:.4f}s\")\n",
    "print(\"=\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b1f0a3-c60e-40a7-8ab9-68c9e080cf57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
