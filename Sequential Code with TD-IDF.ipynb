{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0f754d8-c70e-476d-936d-b2c98978790a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/fellwakh/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ Loading dataset...\n",
      "âœ… Dataset loaded successfully: 10635 rows\n",
      "\n",
      "===============================================\n",
      "ğŸ·ï¸  TOP 10 MOST FREQUENT GENRES\n",
      "===============================================\n",
      "  fiction                   7268\n",
      "  classics                  5467\n",
      "  20th-century              3207\n",
      "  non-fiction               3035\n",
      "  literature                2936\n",
      "  history                   2936\n",
      "  historical-fiction        2632\n",
      "  novels                    2366\n",
      "  historical                2262\n",
      "  romance                   2149\n",
      "\n",
      "===============================================\n",
      "ğŸŒ OVERALL TEXT ANALYSIS (All Books Combined)\n",
      "===============================================\n",
      "\n",
      "ğŸ”¹ Top 15 Words:\n",
      "  the                  35067507\n",
      "  of                   18516551\n",
      "  and                  18392449\n",
      "  to                   15395077\n",
      "  a                    12816898\n",
      "  in                   10117560\n",
      "  i                    7692484\n",
      "  that                 6994246\n",
      "  he                   6969040\n",
      "  was                  6543660\n",
      "  it                   6263874\n",
      "  his                  5327421\n",
      "  with                 4536514\n",
      "  you                  4466103\n",
      "  as                   4446074\n",
      "\n",
      "===============================================\n",
      "ğŸ“Š TF-IDF TOP TERMS (Overall Importance)\n",
      "===============================================\n",
      "   came\n",
      "   come\n",
      "   day\n",
      "   did\n",
      "   en\n",
      "   et\n",
      "   good\n",
      "   great\n",
      "   know\n",
      "   la\n",
      "   le\n",
      "   like\n",
      "   little\n",
      "   man\n",
      "   men\n",
      "   mr\n",
      "   old\n",
      "   que\n",
      "   said\n",
      "   time\n",
      "\n",
      "===============================================\n",
      "â±ï¸  PROCESSING TIME SUMMARY\n",
      "===============================================\n",
      "Total rows processed: 10635\n",
      "Elapsed time: 8 min 21 sec\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import ast\n",
    "import time\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "# ğŸ•’ Ø¨Ø¯Ø¡ Ø§Ù„Ù…Ø¤Ù‚Øª\n",
    "start_time = time.time()\n",
    "\n",
    "# ğŸ§¾ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù\n",
    "print(\"ğŸ“‚ Loading dataset...\")\n",
    "df = pd.read_csv(\"/Users/fellwakh/Downloads/newpar/books_and_genres.csv\")\n",
    "\n",
    "# Ø­Ø°Ù Ø§Ù„Ø¹Ù…ÙˆØ¯ Ø§Ù„Ø²Ø§Ø¦Ø¯ Ù„Ùˆ Ù…ÙˆØ¬ÙˆØ¯\n",
    "if \"Unnamed: 0\" in df.columns:\n",
    "    df = df.drop(columns=[\"Unnamed: 0\"])\n",
    "\n",
    "print(f\"âœ… Dataset loaded successfully: {len(df)} rows\\n\")\n",
    "\n",
    "# ğŸ§¹ ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†ØµÙˆØµ\n",
    "def clean_text(text):\n",
    "    text = re.sub(r\"[^a-zA-Z\\s]\", \" \", str(text))\n",
    "    return text.lower()\n",
    "\n",
    "df[\"clean_text\"] = df[\"text\"].apply(clean_text)\n",
    "\n",
    "# ğŸ­ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø£Ø¯Ø¨ÙŠØ©\n",
    "def extract_genres(genres_str):\n",
    "    try:\n",
    "        genres = ast.literal_eval(genres_str)\n",
    "        if isinstance(genres, (set, list)):\n",
    "            return list(genres)\n",
    "        else:\n",
    "            return []\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "df[\"genre_list\"] = df[\"genres\"].apply(extract_genres)\n",
    "\n",
    "# ===================================================\n",
    "# ğŸ·ï¸  TOP 10 MOST FREQUENT GENRES\n",
    "# ===================================================\n",
    "all_genres = [g for sublist in df[\"genre_list\"] for g in sublist]\n",
    "genre_freq = Counter(all_genres).most_common(10)\n",
    "\n",
    "print(\"===============================================\")\n",
    "print(\"ğŸ·ï¸  TOP 10 MOST FREQUENT GENRES\")\n",
    "print(\"===============================================\")\n",
    "for g, c in genre_freq:\n",
    "    print(f\"  {g:<25} {c}\")\n",
    "\n",
    "# ===================================================\n",
    "# ğŸ”  TOP 15 WORDS\n",
    "# ===================================================\n",
    "print(\"\\n===============================================\")\n",
    "print(\"ğŸŒ OVERALL TEXT ANALYSIS (All Books Combined)\")\n",
    "print(\"===============================================\")\n",
    "\n",
    "# Ø¬Ù…Ø¹ ÙƒÙ„ Ø§Ù„Ù†ØµÙˆØµ ÙÙŠ Ù†Øµ ÙˆØ§Ø­Ø¯\n",
    "all_text = \" \".join(df[\"clean_text\"])\n",
    "all_words = all_text.split()\n",
    "\n",
    "# ğŸ”¹ Ø£ÙƒØ«Ø± 15 ÙƒÙ„Ù…Ø© Ø´ÙŠÙˆØ¹Ù‹Ø§\n",
    "word_freq = Counter(all_words).most_common(15)\n",
    "\n",
    "print(\"\\nğŸ”¹ Top 15 Words:\")\n",
    "for w, c in word_freq:\n",
    "    print(f\"  {w:<20} {c}\")\n",
    "\n",
    "# ===================================================\n",
    "# ğŸ§® TF-IDF (Overall Important Terms)\n",
    "# ===================================================\n",
    "print(\"\\n===============================================\")\n",
    "print(\"ğŸ“Š TF-IDF TOP TERMS (Overall Importance)\")\n",
    "print(\"===============================================\")\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\", max_features=20)\n",
    "tfidf_matrix = vectorizer.fit_transform(df[\"clean_text\"])\n",
    "tfidf_terms = vectorizer.get_feature_names_out()\n",
    "\n",
    "for term in tfidf_terms:\n",
    "    print(\"  \", term)\n",
    "\n",
    "# ğŸ•’ Ø­Ø³Ø§Ø¨ Ø§Ù„Ø²Ù…Ù† Ø§Ù„Ù…Ø³ØªØºØ±Ù‚\n",
    "end_time = time.time()\n",
    "elapsed = end_time - start_time\n",
    "minutes = int(elapsed // 60)\n",
    "seconds = int(elapsed % 60)\n",
    "\n",
    "print(\"\\n===============================================\")\n",
    "print(\"â±ï¸  PROCESSING TIME SUMMARY\")\n",
    "print(\"===============================================\")\n",
    "print(f\"Total rows processed: {len(df)}\")\n",
    "print(f\"Elapsed time: {minutes} min {seconds} sec\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b086a32c-bff8-4010-83db-2fee0daa68fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
